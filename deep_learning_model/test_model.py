import os
import torch
import torchvision
import numpy as np
from models.TransferLearnModels import VGG19_wrapper
from models.models_utils import get_pretrained_image_dim
from data_utils.bin_to_img import generate_and_save_image
from PIL import Image

model_params={"num_of_classes":20, "model_name": 'vgg19', "class_names":['adload', 'agent', 'alureon', 'bho', 'ceeinject', 'cycbot', 'delfinject', 'fakerean', \
                'hotbar', 'lolyda', 'obfuscator', 'onlinegames', 'rbot', 'renos', 'startpage', 'vobfus', 'vundo', 'winwebsec', 'zbot', 'zeroaccess']}
model_path='logs/24-Apr-2022_13_17_32/tl_experiment_1/vgg19.pt'
model = VGG19_wrapper(model_params)
model.load_state_dict(torch.load(model_path))
# print(model)

exe_path='data/OperaSetup.exe'
exe_img_path='data/OperaSetup.png'
data_path='data/test_data/'
pretrained_image_dim = get_pretrained_image_dim(model_params['model_name'])

width=64
for exe in os.listdir(data_path):
    exe_path = os.path.join(data_path, exe)
    exename, file_extension = os.path.splitext(exe_path)
    if file_extension!='.png':
        print("Filename: ", exe)
        exe_img_path = data_path+exe+'.png'
        generate_and_save_image(exe_path, exe_img_path, width)

image_dim_h = width
image_dim_w = width
transform = torchvision.transforms.Compose([
            torchvision.transforms.Resize((pretrained_image_dim, pretrained_image_dim)),
            torchvision.transforms.Lambda(lambda image: image.convert('RGB')),
            torchvision.transforms.ToTensor()
        ])
images=[]
images_filenames=[]
for img in os.listdir(data_path):
    imgg_path = os.path.join(data_path, img)
    exename, file_extension = os.path.splitext(imgg_path)
    if file_extension=='.png':
        print("Image: ", img)
        images_filenames.append(img)
        img = Image.open(imgg_path)
        img = transform(img)
        # img = img.reshape([1, img.shape[0], img.shape[1], img.shape[2]])
        images.append(np.array(img))
        # print("Image shape: ", img.shape)

images = torch.Tensor(images)
pred = model(images)
pred_class_idx = torch.argmax(pred, dim=1)
print(pred_class_idx)
for i, pred_idx in enumerate(pred_class_idx):
    print(images_filenames[i], end=' ')
    print("Predicted family: ", model_params['class_names'][pred_idx])